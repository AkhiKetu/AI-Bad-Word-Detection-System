# ToxicScan â€“ Bangla Toxicity Detection System

ToxicScan is a simple AI-based Bangla text toxicity detector.
It uses a hybrid approach combining:

A labeled dataset (train_data.jsonl)

Similarity matching (Jaccard, Dice, substring)

AI confirmation using Ollama Phi-3

The system identifies different types of toxic content such as:
Abusive, Profane, Political Hate, Religious Hate, Other, and None.
